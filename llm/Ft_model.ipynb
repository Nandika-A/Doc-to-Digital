{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc746b57-7a61-43ba-897f-762069634884",
   "metadata": {},
   "source": [
    "Download the Base model from huggigface:\n",
    "\n",
    "    git lfs install\n",
    "    git clone https://huggingface.co/microsoft/phi-2\n",
    "\n",
    "    \n",
    "Change the model_name to the downloaded location.\n",
    "\n",
    "Download the fine-tuned Checkpoints from:\n",
    "\n",
    "    https://drive.google.com/file/d/1Yx0wgjE9DeKG1tnmDpd1k9WkH94pSH9t/view?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b60595-ba9b-41bc-abe8-6a0ed150fb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8571a3-d60b-4666-8ce5-e2b6361a9ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:36<00:00, 18.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "os.environ['WANDB_DISABLED']=\"true\"\n",
    "\n",
    "base_model_id = \"microsoft/phi-2\"\n",
    "device_maps = {'':'cpu'}\n",
    "model_name = \"C:\\\\Users\\\\Acer\\\\Downloads\\\\phi-2\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name,torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bcf4c96-9e16-4c12-a2d9-767596150829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(model_name, add_bos_token=True, trust_remote_code=True, use_fast=False)\n",
    "eval_tokenizer.pad_token = eval_tokenizer.eos_token\n",
    "\n",
    "def gen(model,p, maxlen=100, sample=True):\n",
    "    toks = eval_tokenizer(p, return_tensors=\"pt\")\n",
    "    toks = toks.to('cpu')\n",
    "    res = model.generate(**toks, max_new_tokens=maxlen, do_sample=sample,num_return_sequences=1,temperature=0.1,num_beams=1,top_p=0.95,).to('cpu')\n",
    "    return eval_tokenizer.batch_decode(res,skip_special_tokens=True)\n",
    "\n",
    "# #download the model: https://drive.google.com/file/d/1Yx0wgjE9DeKG1tnmDpd1k9WkH94pSH9t/view?usp=sharing\n",
    "# #!unzip \"/content/model.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340a3224-4935-456c-a6f1-5753e08ee29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"C:\\\\Users\\\\Acer\\\\Downloads\\\\ft_model\\\\model\\\\final-checkpoint\\\\checkpoint-1000\",torch_dtype=torch.float16,is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "125e4b60-044b-4531-b138-60bec57ffb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(dialogue):\n",
    "  prompt = f\"Instruct: Explain the following conversation as a Teacher.\\n{dialogue}\\nOutput:\\n\"\n",
    "\n",
    "  peft_model_res = gen(ft_model,prompt,25)\n",
    "  peft_model_output = peft_model_res[0].split('Output:\\n')[1]\n",
    "  prefix, success, result = peft_model_output.partition('\\n')\n",
    "\n",
    "\n",
    "  return peft_model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca092c26-4feb-46f0-bb3d-d7babd11ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe72ff2-53f6-4391-ac87-a2f4704d20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "st = time.time()\n",
    "\n",
    "res = response(\"What is Science?.\")\n",
    "\n",
    "ed = time.time()\n",
    "\n",
    "print(\"Time Taken: \", ed - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a13cf36-1e39-4cf8-ac62-b98db3691b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "res = response(\"What is Science?.\")\n",
    "prefix, success, result = res[0].split('Output:\\n')[1].partition('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4d243e-cba7-4f8a-af62-0d531275f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science is the study of the natural world. It is a systematic way of investigating the world around us.\n"
     ]
    }
   ],
   "source": [
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4940ac3-af3b-488a-82c2-75612547bb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
